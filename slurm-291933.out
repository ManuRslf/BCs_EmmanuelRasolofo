wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: manurslf (manurslf301) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250317_195155-aqbj0caq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DS midjourney dataset - AT 2 (20250317-195154)
wandb: ⭐️ View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: 🚀 View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/aqbj0caq
Operation on cuda
Using midjourney DATASET, Classes in dataset: ['ai', 'nature']
Additional tokens : 2
Training...
Loss epoch 0 -> 1.21813
Loss epoch 1 -> 0.33949
Loss epoch 2 -> 0.14669
Loss epoch 3 -> 0.03980
Loss epoch 4 -> 0.01202
Loss epoch 5 -> 0.01021
Loss epoch 6 -> 0.00354
Loss epoch 7 -> 0.00367
Loss epoch 8 -> 0.00487
Loss epoch 9 -> 0.00850
Loss epoch 10 -> 0.00509
Loss epoch 11 -> 0.00235
Loss epoch 12 -> 0.00107
Loss epoch 13 -> 0.00011
Loss epoch 14 -> 0.00004
Loss epoch 15 -> 0.00003
Loss epoch 16 -> 0.00002
Loss epoch 17 -> 0.00002
Loss epoch 18 -> 0.00002
Loss epoch 19 -> 0.00002
Loss epoch 20 -> 0.00002
Loss epoch 21 -> 0.00001
Loss epoch 22 -> 0.00001
Loss epoch 23 -> 0.00001
Loss epoch 24 -> 0.00001
Loss epoch 25 -> 0.00001
Loss epoch 26 -> 0.00001
Loss epoch 27 -> 0.00001
Loss epoch 28 -> 0.00001
Loss epoch 29 -> 0.00001
Loss epoch 30 -> 0.00001
Loss epoch 31 -> 0.00001
Loss epoch 32 -> 0.00001
Loss epoch 33 -> 0.00001
Loss epoch 34 -> 0.00001
Loss epoch 35 -> 0.00001
Loss epoch 36 -> 0.00001
Loss epoch 37 -> 0.00001
Loss epoch 38 -> 0.00001
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: Test/Accuracy ▁▆▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:    Train/Loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb: Test/Accuracy 0.897
wandb:    Train/Loss 1e-05
wandb:         epoch 39
wandb: 
wandb: 🚀 View run DS midjourney dataset - AT 2 (20250317-195154) at: https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/aqbj0caq
wandb: ⭐️ View project at: https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250317_195155-aqbj0caq/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250317_203351-z53tk6bf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DS midjourney dataset - AT 3 (20250317-195154)
wandb: ⭐️ View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: 🚀 View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/z53tk6bf
Loss epoch 39 -> 0.00001
end...
Accuracy : 0.897
Classification report:
              precision    recall  f1-score   support

          ia       0.89      0.91      0.90       500
      nature       0.91      0.89      0.90       500

    accuracy                           0.90      1000
   macro avg       0.90      0.90      0.90      1000
weighted avg       0.90      0.90      0.90      1000

-----------------------------------------------------------------------------------------------------------
Additional tokens : 3
Training...
Loss epoch 0 -> 1.17904
Loss epoch 1 -> 0.34509
Loss epoch 2 -> 0.14002
Loss epoch 3 -> 0.02894
Loss epoch 4 -> 0.00582
Loss epoch 5 -> 0.00186
Loss epoch 6 -> 0.00057
Loss epoch 7 -> 0.00070
Loss epoch 8 -> 0.00006
Loss epoch 9 -> 0.00003
Loss epoch 10 -> 0.00002
Loss epoch 11 -> 0.00002
Loss epoch 12 -> 0.00002
Loss epoch 13 -> 0.00001
Loss epoch 14 -> 0.00001
Loss epoch 15 -> 0.00001
Loss epoch 16 -> 0.00001
Loss epoch 17 -> 0.00001
Loss epoch 18 -> 0.00001
Loss epoch 19 -> 0.00001
Loss epoch 20 -> 0.00001
Loss epoch 21 -> 0.00001
Loss epoch 22 -> 0.00001
Loss epoch 23 -> 0.00001
Loss epoch 24 -> 0.00001
Loss epoch 25 -> 0.00001
Loss epoch 26 -> 0.00001
Loss epoch 27 -> 0.00001
Loss epoch 28 -> 0.00001
Loss epoch 29 -> 0.00001
Loss epoch 30 -> 0.00001
Loss epoch 31 -> 0.00001
Loss epoch 32 -> 0.00001
Loss epoch 33 -> 0.00001
Loss epoch 34 -> 0.00001
Loss epoch 35 -> 0.00001
Loss epoch 36 -> 0.00001
Loss epoch 37 -> 0.00001
Loss epoch 38 -> 0.00001
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: Test/Accuracy ▁▇▇█████████████████████████████████████
wandb:    Train/Loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb: Test/Accuracy 0.903
wandb:    Train/Loss 1e-05
wandb:         epoch 39
wandb: 
wandb: 🚀 View run DS midjourney dataset - AT 3 (20250317-195154) at: https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/z53tk6bf
wandb: ⭐️ View project at: https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250317_203351-z53tk6bf/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250317_211607-zqbf3tkz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DS midjourney dataset - AT 4 (20250317-195154)
wandb: ⭐️ View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: 🚀 View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/zqbf3tkz
Loss epoch 39 -> 0.00001
end...
Accuracy : 0.903
Classification report:
              precision    recall  f1-score   support

          ia       0.89      0.92      0.90       500
      nature       0.92      0.89      0.90       500

    accuracy                           0.90      1000
   macro avg       0.90      0.90      0.90      1000
weighted avg       0.90      0.90      0.90      1000

-----------------------------------------------------------------------------------------------------------
Additional tokens : 4
Training...
Loss epoch 0 -> 1.12958
Loss epoch 1 -> 0.30228
Loss epoch 2 -> 0.10815
Loss epoch 3 -> 0.02234
Loss epoch 4 -> 0.01400
Loss epoch 5 -> 0.01145
Loss epoch 6 -> 0.01030
Loss epoch 7 -> 0.00336
Loss epoch 8 -> 0.00158
Loss epoch 9 -> 0.00019
Loss epoch 10 -> 0.00004
Loss epoch 11 -> 0.00003
Loss epoch 12 -> 0.00002
Loss epoch 13 -> 0.00002
Loss epoch 14 -> 0.00002
Loss epoch 15 -> 0.00001
Loss epoch 16 -> 0.00001
Loss epoch 17 -> 0.00001
Loss epoch 18 -> 0.00001
Loss epoch 19 -> 0.00001
Loss epoch 20 -> 0.00001
Loss epoch 21 -> 0.00001
Loss epoch 22 -> 0.00001
Loss epoch 23 -> 0.00001
Loss epoch 24 -> 0.00001
Loss epoch 25 -> 0.00001
Loss epoch 26 -> 0.00001
Loss epoch 27 -> 0.00001
Loss epoch 28 -> 0.00001
Loss epoch 29 -> 0.00001
Loss epoch 30 -> 0.00001
Loss epoch 31 -> 0.00001
Loss epoch 32 -> 0.00001
Loss epoch 33 -> 0.00001
Loss epoch 34 -> 0.00001
Loss epoch 35 -> 0.00001
Loss epoch 36 -> 0.00001
Loss epoch 37 -> 0.00001
Loss epoch 38 -> 0.00001
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: Test/Accuracy ▁▇▇▇███▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:    Train/Loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb: Test/Accuracy 0.897
wandb:    Train/Loss 1e-05
wandb:         epoch 39
wandb: 
wandb: 🚀 View run DS midjourney dataset - AT 4 (20250317-195154) at: https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/zqbf3tkz
wandb: ⭐️ View project at: https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250317_211607-zqbf3tkz/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250317_215820-p0nhwlrw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DS midjourney dataset - AT 5 (20250317-195154)
wandb: ⭐️ View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: 🚀 View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/p0nhwlrw
Loss epoch 39 -> 0.00001
end...
Accuracy : 0.897
Classification report:
              precision    recall  f1-score   support

          ia       0.92      0.87      0.89       500
      nature       0.88      0.93      0.90       500

    accuracy                           0.90      1000
   macro avg       0.90      0.90      0.90      1000
weighted avg       0.90      0.90      0.90      1000

-----------------------------------------------------------------------------------------------------------
Additional tokens : 5
Training...
Loss epoch 0 -> 1.19648
Loss epoch 1 -> 0.33252
Loss epoch 2 -> 0.13222
Loss epoch 3 -> 0.02728
Loss epoch 4 -> 0.00731
Loss epoch 5 -> 0.00514
Loss epoch 6 -> 0.01056
Loss epoch 7 -> 0.01565
Loss epoch 8 -> 0.02350
Loss epoch 9 -> 0.00752
Loss epoch 10 -> 0.00331
Loss epoch 11 -> 0.00189
Loss epoch 12 -> 0.00017
Loss epoch 13 -> 0.00005
Loss epoch 14 -> 0.00004
Loss epoch 15 -> 0.00003
Loss epoch 16 -> 0.00003
Loss epoch 17 -> 0.00002
Loss epoch 18 -> 0.00002
Loss epoch 19 -> 0.00002
Loss epoch 20 -> 0.00002
Loss epoch 21 -> 0.00002
Loss epoch 22 -> 0.00002
Loss epoch 23 -> 0.00001
Loss epoch 24 -> 0.00001
Loss epoch 25 -> 0.00001
Loss epoch 26 -> 0.00001
Loss epoch 27 -> 0.00001
Loss epoch 28 -> 0.00001
Loss epoch 29 -> 0.00001
Loss epoch 30 -> 0.00001
Loss epoch 31 -> 0.00001
Loss epoch 32 -> 0.00001
Loss epoch 33 -> 0.00001
Loss epoch 34 -> 0.00001
Loss epoch 35 -> 0.00001
Loss epoch 36 -> 0.00001
Loss epoch 37 -> 0.00001
Loss epoch 38 -> 0.00001
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: Test/Accuracy ▁▇▇▇███▇▇▇▇█████████████████████████████
wandb:    Train/Loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb: Test/Accuracy 0.904
wandb:    Train/Loss 1e-05
wandb:         epoch 39
wandb: 
wandb: 🚀 View run DS midjourney dataset - AT 5 (20250317-195154) at: https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/p0nhwlrw
wandb: ⭐️ View project at: https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250317_215820-p0nhwlrw/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250317_224035-16qftjgh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DS midjourney dataset - AT 6 (20250317-195154)
wandb: ⭐️ View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: 🚀 View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/16qftjgh
Loss epoch 39 -> 0.00001
end...
Accuracy : 0.904
Classification report:
              precision    recall  f1-score   support

          ia       0.90      0.91      0.90       500
      nature       0.91      0.90      0.90       500

    accuracy                           0.90      1000
   macro avg       0.90      0.90      0.90      1000
weighted avg       0.90      0.90      0.90      1000

-----------------------------------------------------------------------------------------------------------
Additional tokens : 6
Training...
Loss epoch 0 -> 1.16802
Loss epoch 1 -> 0.32007
Loss epoch 2 -> 0.12755
Loss epoch 3 -> 0.02424
Loss epoch 4 -> 0.01486
Loss epoch 5 -> 0.01067
Loss epoch 6 -> 0.02187
Loss epoch 7 -> 0.00740
Loss epoch 8 -> 0.00196
Loss epoch 9 -> 0.00027
Loss epoch 10 -> 0.00005
Loss epoch 11 -> 0.00004
Loss epoch 12 -> 0.00003
Loss epoch 13 -> 0.00003
Loss epoch 14 -> 0.00002
Loss epoch 15 -> 0.00002
Loss epoch 16 -> 0.00002
Loss epoch 17 -> 0.00002
Loss epoch 18 -> 0.00002
Loss epoch 19 -> 0.00001
Loss epoch 20 -> 0.00001
Loss epoch 21 -> 0.00001
Loss epoch 22 -> 0.00001
Loss epoch 23 -> 0.00001
Loss epoch 24 -> 0.00001
Loss epoch 25 -> 0.00001
Loss epoch 26 -> 0.00001
Loss epoch 27 -> 0.00001
Loss epoch 28 -> 0.00001
Loss epoch 29 -> 0.00001
Loss epoch 30 -> 0.00001
Loss epoch 31 -> 0.00001
Loss epoch 32 -> 0.00001
Loss epoch 33 -> 0.00001
Loss epoch 34 -> 0.00001
Loss epoch 35 -> 0.00001
Loss epoch 36 -> 0.00001
Loss epoch 37 -> 0.00001
Loss epoch 38 -> 0.00001
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: Test/Accuracy ▁▅▇██▇▇▇████████████████████████████████
wandb:    Train/Loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb: Test/Accuracy 0.904
wandb:    Train/Loss 1e-05
wandb:         epoch 39
wandb: 
wandb: 🚀 View run DS midjourney dataset - AT 6 (20250317-195154) at: https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/16qftjgh
wandb: ⭐️ View project at: https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250317_224035-16qftjgh/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250317_232254-7y4v52ug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DS midjourney dataset - AT 7 (20250317-195154)
wandb: ⭐️ View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: 🚀 View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/7y4v52ug
Loss epoch 39 -> 0.00001
end...
Accuracy : 0.904
Classification report:
              precision    recall  f1-score   support

          ia       0.90      0.91      0.90       500
      nature       0.91      0.90      0.90       500

    accuracy                           0.90      1000
   macro avg       0.90      0.90      0.90      1000
weighted avg       0.90      0.90      0.90      1000

-----------------------------------------------------------------------------------------------------------
Additional tokens : 7
Training...
Loss epoch 0 -> 1.20839
Loss epoch 1 -> 0.34382
Loss epoch 2 -> 0.13369
Loss epoch 3 -> 0.02660
Loss epoch 4 -> 0.00998
Loss epoch 5 -> 0.00808
Loss epoch 6 -> 0.00483
Loss epoch 7 -> 0.01103
Loss epoch 8 -> 0.01652
Loss epoch 9 -> 0.00570
Loss epoch 10 -> 0.00328
Loss epoch 11 -> 0.00161
Loss epoch 12 -> 0.00121
Loss epoch 13 -> 0.00005
Loss epoch 14 -> 0.00003
Loss epoch 15 -> 0.00002
Loss epoch 16 -> 0.00002
Loss epoch 17 -> 0.00002
Loss epoch 18 -> 0.00001
Loss epoch 19 -> 0.00001
Loss epoch 20 -> 0.00001
Loss epoch 21 -> 0.00001
Loss epoch 22 -> 0.00001
Loss epoch 23 -> 0.00001
Loss epoch 24 -> 0.00001
Loss epoch 25 -> 0.00001
Loss epoch 26 -> 0.00001
Loss epoch 27 -> 0.00001
Loss epoch 28 -> 0.00001
Loss epoch 29 -> 0.00001
Loss epoch 30 -> 0.00001
Loss epoch 31 -> 0.00001
Loss epoch 32 -> 0.00001
Loss epoch 33 -> 0.00001
Loss epoch 34 -> 0.00001
Loss epoch 35 -> 0.00001
Loss epoch 36 -> 0.00001
Loss epoch 37 -> 0.00001
Loss epoch 38 -> 0.00001
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: Test/Accuracy ▁▆▇█▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:    Train/Loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb: Test/Accuracy 0.909
wandb:    Train/Loss 1e-05
wandb:         epoch 39
wandb: 
wandb: 🚀 View run DS midjourney dataset - AT 7 (20250317-195154) at: https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/7y4v52ug
wandb: ⭐️ View project at: https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250317_232254-7y4v52ug/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250318_000520-fgzh0jfz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DS midjourney dataset - AT 8 (20250317-195154)
wandb: ⭐️ View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: 🚀 View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/fgzh0jfz
Loss epoch 39 -> 0.00001
end...
Accuracy : 0.909
Classification report:
              precision    recall  f1-score   support

          ia       0.93      0.89      0.91       500
      nature       0.89      0.93      0.91       500

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000

-----------------------------------------------------------------------------------------------------------
Additional tokens : 8
Training...
Loss epoch 0 -> 1.13069
Loss epoch 1 -> 0.30442
Loss epoch 2 -> 0.11651
Loss epoch 3 -> 0.01726
Loss epoch 4 -> 0.01015
Loss epoch 5 -> 0.01479
Loss epoch 6 -> 0.02094
Loss epoch 7 -> 0.00995
Loss epoch 8 -> 0.00243
Loss epoch 9 -> 0.00037
Loss epoch 10 -> 0.00006
Loss epoch 11 -> 0.00003
Loss epoch 12 -> 0.00002
Loss epoch 13 -> 0.00002
Loss epoch 14 -> 0.00002
Loss epoch 15 -> 0.00002
Loss epoch 16 -> 0.00002
Loss epoch 17 -> 0.00001
Loss epoch 18 -> 0.00001
Loss epoch 19 -> 0.00001
Loss epoch 20 -> 0.00001
Loss epoch 21 -> 0.00001
Loss epoch 22 -> 0.00001
Loss epoch 23 -> 0.00001
Loss epoch 24 -> 0.00001
Loss epoch 25 -> 0.00001
Loss epoch 26 -> 0.00001
Loss epoch 27 -> 0.00001
Loss epoch 28 -> 0.00001
Loss epoch 29 -> 0.00001
Loss epoch 30 -> 0.00001
Loss epoch 31 -> 0.00001
Loss epoch 32 -> 0.00001
Loss epoch 33 -> 0.00001
Loss epoch 34 -> 0.00001
Loss epoch 35 -> 0.00001
Loss epoch 36 -> 0.00001
Loss epoch 37 -> 0.00001
Loss epoch 38 -> 0.00001
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: Test/Accuracy ▁▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:    Train/Loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb: Test/Accuracy 0.891
wandb:    Train/Loss 1e-05
wandb:         epoch 39
wandb: 
wandb: 🚀 View run DS midjourney dataset - AT 8 (20250317-195154) at: https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/fgzh0jfz
wandb: ⭐️ View project at: https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250318_000520-fgzh0jfz/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250318_004749-k7xq2mse
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DS midjourney dataset - AT 9 (20250317-195154)
wandb: ⭐️ View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: 🚀 View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/k7xq2mse
Loss epoch 39 -> 0.00001
end...
Accuracy : 0.891
Classification report:
              precision    recall  f1-score   support

          ia       0.91      0.87      0.89       500
      nature       0.88      0.91      0.89       500

    accuracy                           0.89      1000
   macro avg       0.89      0.89      0.89      1000
weighted avg       0.89      0.89      0.89      1000

-----------------------------------------------------------------------------------------------------------
Additional tokens : 9
Training...
Loss epoch 0 -> 1.16526
Loss epoch 1 -> 0.30753
Loss epoch 2 -> 0.11328
Loss epoch 3 -> 0.01822
Loss epoch 4 -> 0.03060
Loss epoch 5 -> 0.00611
Loss epoch 6 -> 0.01218
Loss epoch 7 -> 0.00541
Loss epoch 8 -> 0.00245
Loss epoch 9 -> 0.00353
Loss epoch 10 -> 0.01115
Loss epoch 11 -> 0.00285
Loss epoch 12 -> 0.00083
Loss epoch 13 -> 0.00019
Loss epoch 14 -> 0.00004
Loss epoch 15 -> 0.00003
Loss epoch 16 -> 0.00002
Loss epoch 17 -> 0.00002
Loss epoch 18 -> 0.00002
Loss epoch 19 -> 0.00002
Loss epoch 20 -> 0.00002
Loss epoch 21 -> 0.00002
Loss epoch 22 -> 0.00001
Loss epoch 23 -> 0.00001
Loss epoch 24 -> 0.00001
Loss epoch 25 -> 0.00001
Loss epoch 26 -> 0.00001
Loss epoch 27 -> 0.00001
Loss epoch 28 -> 0.00001
Loss epoch 29 -> 0.00001
Loss epoch 30 -> 0.00001
Loss epoch 31 -> 0.00001
Loss epoch 32 -> 0.00001
Loss epoch 33 -> 0.00001
Loss epoch 34 -> 0.00001
Loss epoch 35 -> 0.00001
Loss epoch 36 -> 0.00001
Loss epoch 37 -> 0.00001
Loss epoch 38 -> 0.00001
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: Test/Accuracy ▁▆██▇██▇▇▇▇▇▇██▇████████████████████████
wandb:    Train/Loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb: Test/Accuracy 0.901
wandb:    Train/Loss 1e-05
wandb:         epoch 39
wandb: 
wandb: 🚀 View run DS midjourney dataset - AT 9 (20250317-195154) at: https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/k7xq2mse
wandb: ⭐️ View project at: https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250318_004749-k7xq2mse/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250318_013020-yrr868me
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run DS midjourney dataset - AT 10 (20250317-195154)
wandb: ⭐️ View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: 🚀 View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/yrr868me
Loss epoch 39 -> 0.00001
end...
Accuracy : 0.901
Classification report:
              precision    recall  f1-score   support

          ia       0.91      0.89      0.90       500
      nature       0.89      0.91      0.90       500

    accuracy                           0.90      1000
   macro avg       0.90      0.90      0.90      1000
weighted avg       0.90      0.90      0.90      1000

-----------------------------------------------------------------------------------------------------------
Additional tokens : 10
Training...
Loss epoch 0 -> 1.14791
Loss epoch 1 -> 0.34855
Loss epoch 2 -> 0.12966
Loss epoch 3 -> 0.02331
Loss epoch 4 -> 0.01251
Loss epoch 5 -> 0.00985
Loss epoch 6 -> 0.00875
Loss epoch 7 -> 0.00530
Loss epoch 8 -> 0.01237
Loss epoch 9 -> 0.00639
Loss epoch 10 -> 0.00139
Loss epoch 11 -> 0.00015
Loss epoch 12 -> 0.00005
Loss epoch 13 -> 0.00003
Loss epoch 14 -> 0.00003
Loss epoch 15 -> 0.00002
Loss epoch 16 -> 0.00002
Loss epoch 17 -> 0.00002
Loss epoch 18 -> 0.00002
Loss epoch 19 -> 0.00002
Loss epoch 20 -> 0.00001
Loss epoch 21 -> 0.00001
Loss epoch 22 -> 0.00001
Loss epoch 23 -> 0.00001
Loss epoch 24 -> 0.00001
Loss epoch 25 -> 0.00001
Loss epoch 26 -> 0.00001
Loss epoch 27 -> 0.00001
Loss epoch 28 -> 0.00001
Loss epoch 29 -> 0.00001
Loss epoch 30 -> 0.00001
Loss epoch 31 -> 0.00001
Loss epoch 32 -> 0.00001
Loss epoch 33 -> 0.00001
Loss epoch 34 -> 0.00001
Loss epoch 35 -> 0.00001
Loss epoch 36 -> 0.00001
Loss epoch 37 -> 0.00001
Loss epoch 38 -> 0.00001
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: Test/Accuracy ▁▇██████████████████████████████████████
wandb:    Train/Loss █▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:         epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb: Test/Accuracy 0.906
wandb:    Train/Loss 1e-05
wandb:         epoch 39
wandb: 
wandb: 🚀 View run DS midjourney dataset - AT 10 (20250317-195154) at: https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/yrr868me
wandb: ⭐️ View project at: https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250318_013020-yrr868me/logs
Loss epoch 39 -> 0.00001
end...
Accuracy : 0.906
Classification report:
              precision    recall  f1-score   support

          ia       0.90      0.91      0.91       500
      nature       0.91      0.90      0.91       500

    accuracy                           0.91      1000
   macro avg       0.91      0.91      0.91      1000
weighted avg       0.91      0.91      0.91      1000

-----------------------------------------------------------------------------------------------------------

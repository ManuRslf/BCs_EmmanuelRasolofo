wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: manurslf (manurslf301) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250430_142629-vvc1zamr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run AT midjourney R224 dataset 20250430-142628
wandb: ‚≠êÔ∏è View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: üöÄ View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/vvc1zamr
Date d'entra√Ænement: 20250430-142628
Mode: run
Images redimensionn√©es en 224x224
Tokens additionnels (lab): [0, 10, 60, 100, 150]
LLMA (lab): 6 couches, taille 384
Batch size (lab): 16, LR (lab): 0.0004, √âpoques (lab): 80
LLAMA num hidden : [1, 6, 12, 16]


CECI EST UN ENTRAINEMENT EN VARIANT LA TAILLE DE COUCHES CACHEES DE LLAMA


Op√©ration sur cuda
Dataset utilis√© 'midjourney' - Classes: ['ai', 'nature']
----------------------------------------------------------------------------------------------------
[midjourney]Entra√Ænement avec 6 couche de llama et de tailles 128 pour chaque couches
TRAINING...
Traceback (most recent call last):
  File "/home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/main.py", line 153, in <module>
    Config_model_run('llama2')
  File "/home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/main.py", line 102, in Config_model_run
    run_experiment_llama2(Config.MODEL, Config.WANDB_LOG, Config.DECREASING_LR_LAB)
  File "/home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/util.py", line 461, in run_experiment_llama2
    model = train_model_llama_params(model_name,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/util.py", line 137, in train_model_llama_params
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "/home/users/r/rasolof2/miniconda3/envs/project/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/users/r/rasolof2/miniconda3/envs/project/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/CustomClassifier.py", line 72, in forward
    features = torch.cat((features, add_tokens_expanded), dim=1)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 384 but got size 128 for tensor number 1 in the list.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mAT midjourney R224 dataset 20250430-142628[0m at: [34mhttps://wandb.ai/manurslf301/Encoder-DecoderProject/runs/vvc1zamr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250430_142629-vvc1zamr/logs[0m
srun: error: gpu003: task 0: Exited with exit code 1

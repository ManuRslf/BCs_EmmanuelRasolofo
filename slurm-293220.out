wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: manurslf (manurslf301) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250320_095830-f93d0xfl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Acc. evol. midjourney(20250320-095830)
wandb: â­ï¸ View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: ðŸš€ View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/f93d0xfl
Operation on cuda
Using midjourney DATASET, Classes in dataset: ['ai', 'nature']
Additional tokens : 0
Training...
Loss epoch 0 -> 0.47456
Loss epoch 1 -> 0.10539
Loss epoch 2 -> 0.03554
Loss epoch 3 -> 0.04009
Loss epoch 4 -> 0.01933
Loss epoch 5 -> 0.01834
Loss epoch 6 -> 0.01464
Loss epoch 7 -> 0.01727
Loss epoch 8 -> 0.01138
Loss epoch 9 -> 0.00725
Loss epoch 10 -> 0.00790
Loss epoch 11 -> 0.00341
Loss epoch 12 -> 0.00531
Loss epoch 13 -> 0.00536
Loss epoch 14 -> 0.00244
Loss epoch 15 -> 0.00373
Loss epoch 16 -> 0.01136
Loss epoch 17 -> 0.01619
Loss epoch 18 -> 0.00870
Loss epoch 19 -> 0.01497
Loss epoch 20 -> 0.01427
Loss epoch 21 -> 0.01450
Loss epoch 22 -> 0.00777
Loss epoch 23 -> 0.00054
Loss epoch 24 -> 0.00039
Loss epoch 25 -> 0.00304
Loss epoch 26 -> 0.00868
Loss epoch 27 -> 0.01343
Loss epoch 28 -> 0.02101
Loss epoch 29 -> 0.00428
Loss epoch 30 -> 0.00620
Loss epoch 31 -> 0.00883
Loss epoch 32 -> 0.01177
Loss epoch 33 -> 0.00233
Loss epoch 34 -> 0.00206
Loss epoch 35 -> 0.00071
Loss epoch 36 -> 0.00008
Loss epoch 37 -> 0.00006
Loss epoch 38 -> 0.00005
Loss epoch 39 -> 0.00005
Loss epoch 40 -> 0.00004
Loss epoch 41 -> 0.00004
Loss epoch 42 -> 0.00003
Loss epoch 43 -> 0.00003
Loss epoch 44 -> 0.00003
Loss epoch 45 -> 0.00003
Loss epoch 46 -> 0.00003
Loss epoch 47 -> 0.00002
Loss epoch 48 -> 0.00002
Loss epoch 49 -> 0.00002
Loss epoch 50 -> 0.00002
Loss epoch 51 -> 0.00002
Loss epoch 52 -> 0.00002
Loss epoch 53 -> 0.00002
Loss epoch 54 -> 0.00002
Loss epoch 55 -> 0.00002
Loss epoch 56 -> 0.00002
Loss epoch 57 -> 0.00002
Loss epoch 58 -> 0.00001
Loss epoch 59 -> 0.00001
Loss epoch 60 -> 0.00001
Loss epoch 61 -> 0.00001
Loss epoch 62 -> 0.00001
Loss epoch 63 -> 0.00001
Loss epoch 64 -> 0.00001
Loss epoch 65 -> 0.00001
Loss epoch 66 -> 0.00001
Loss epoch 67 -> 0.00001
Loss epoch 68 -> 0.00001
Loss epoch 69 -> 0.00001
Loss epoch 70 -> 0.00001
Loss epoch 71 -> 0.00001
Loss epoch 72 -> 0.00001
Loss epoch 73 -> 0.00001
Loss epoch 74 -> 0.00001
Loss epoch 75 -> 0.00001
Loss epoch 76 -> 0.00001
Loss epoch 77 -> 0.00001
Loss epoch 78 -> 0.00001
Loss epoch 79 -> 0.00001
Loss epoch 80 -> 0.00001
Loss epoch 81 -> 0.00001
Loss epoch 82 -> 0.00001
Loss epoch 83 -> 0.00001
Loss epoch 84 -> 0.00001
Loss epoch 85 -> 0.00001
Loss epoch 86 -> 0.00001
Loss epoch 87 -> 0.00001
Loss epoch 88 -> 0.00001
Loss epoch 89 -> 0.00001
Loss epoch 90 -> 0.00001
Loss epoch 91 -> 0.00001
Loss epoch 92 -> 0.00001
Loss epoch 93 -> 0.00001
Loss epoch 94 -> 0.00001
Loss epoch 95 -> 0.00001
Loss epoch 96 -> 0.00001
Loss epoch 97 -> 0.00001
Loss epoch 98 -> 0.00001
wandb: uploading history steps 99-99, summary, console lines 101-102
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: Test/Accuracy â–â–†â–„â–…â–‡â–†â–…â–„â–†â–‡â–‡â–ˆâ–‡â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    Train/Loss â–ˆâ–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb: Test/Accuracy 0.894
wandb:    Train/Loss 1e-05
wandb:         epoch 99
wandb: 
wandb: ðŸš€ View run Acc. evol. midjourney(20250320-095830) at: https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/f93d0xfl
wandb: â­ï¸ View project at: https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250320_095830-f93d0xfl/logs
Loss epoch 99 -> 0.00001
end...
Accuracy : 0.894
Classification report:
              precision    recall  f1-score   support

          ia       0.88      0.91      0.90       500
      nature       0.91      0.88      0.89       500

    accuracy                           0.89      1000
   macro avg       0.89      0.89      0.89      1000
weighted avg       0.89      0.89      0.89      1000

-----------------------------------------------------------------------------------------------------------
wandb: ERROR You must call wandb.init() before wandb.log()
Traceback (most recent call last):
  File "/home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/utils.py", line 273, in <module>
    plot_accuracy(configurations.MODEL,
  File "/home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/utils.py", line 245, in plot_accuracy
    wandb.log({
  File "/home/users/r/rasolof2/miniconda3/envs/project/lib/python3.12/site-packages/wandb/sdk/lib/preinit.py", line 36, in preinit_wrapper
    raise wandb.Error(f"You must call wandb.init() before {name}()")
wandb.errors.errors.Error: You must call wandb.init() before wandb.log()
srun: error: gpu002: task 0: Exited with exit code 1

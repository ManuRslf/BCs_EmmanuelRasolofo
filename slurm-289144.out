wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: manurslf (manurslf301) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250314_110934-0mutbe73
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Training on midjourney dataset - Add tokens 2
wandb: â­ï¸ View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: ðŸš€ View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/0mutbe73
Operation on cuda
Using midjourney DATASET, Classes in dataset: ['ai', 'nature']
Additional tokens : 2
Training...
Loss epoch 0 -> 0.96158
Loss epoch 1 -> 0.23592
Loss epoch 2 -> 0.10616
Loss epoch 3 -> 0.04668
Loss epoch 4 -> 0.04614
Loss epoch 5 -> 0.01885
Loss epoch 6 -> 0.02675
Loss epoch 7 -> 0.03698
Loss epoch 8 -> 0.04227
Loss epoch 9 -> 0.04788
Loss epoch 10 -> 0.01522
Loss epoch 11 -> 0.01236
Loss epoch 12 -> 0.02231
Loss epoch 13 -> 0.01788
Loss epoch 14 -> 0.00888
Loss epoch 15 -> 0.01202
Loss epoch 16 -> 0.01589
Loss epoch 17 -> 0.01504
Loss epoch 18 -> 0.00667
Loss epoch 19 -> 0.01308
Loss epoch 20 -> 0.01847
Loss epoch 21 -> 0.01733
Loss epoch 22 -> 0.01967
Loss epoch 23 -> 0.02575
Loss epoch 24 -> 0.06466
Loss epoch 25 -> 0.02421
Loss epoch 26 -> 0.00840
Loss epoch 27 -> 0.00472
Loss epoch 28 -> 0.01205
Loss epoch 29 -> 0.01433
Loss epoch 30 -> 0.01326
Loss epoch 31 -> 0.00287
Loss epoch 32 -> 0.00018
Loss epoch 33 -> 0.00004
Loss epoch 34 -> 0.00003
Loss epoch 35 -> 0.00002
Loss epoch 36 -> 0.00002
Loss epoch 37 -> 0.00002
Loss epoch 38 -> 0.00002
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: Test/Accuracy â–â–„â–ƒâ–…â–…â–†â–…â–…â–†â–‡â–†â–‡â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–†â–„â–ˆâ–‡â–†â–ˆâ–ˆâ–†â–ˆâ–†â–‡â–‡â–†â–†â–†â–†â–†â–†
wandb:    Train/Loss â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb: Test/Accuracy 0.897
wandb:    Train/Loss 1e-05
wandb:         epoch 39
wandb: 
wandb: ðŸš€ View run Training on midjourney dataset - Add tokens 2 at: https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/0mutbe73
wandb: â­ï¸ View project at: https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250314_110934-0mutbe73/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250314_115135-5ukenb5o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Training on midjourney dataset - Add tokens 3
wandb: â­ï¸ View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: ðŸš€ View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/5ukenb5o
Loss epoch 39 -> 0.00001
end...
Accuracy : 0.897
Classification report:
              precision    recall  f1-score   support

          ia       0.89      0.90      0.90       500
      nature       0.90      0.89      0.90       500

    accuracy                           0.90      1000
   macro avg       0.90      0.90      0.90      1000
weighted avg       0.90      0.90      0.90      1000

-----------------------------------------------------------------------------------------------------------
Additional tokens : 3
Training...
Loss epoch 0 -> 1.04582
Loss epoch 1 -> 0.33250
Loss epoch 2 -> 0.14318
Loss epoch 3 -> 0.05953
Loss epoch 4 -> 0.05804
Loss epoch 5 -> 0.04203
Loss epoch 6 -> 0.03990
Loss epoch 7 -> 0.03370
Loss epoch 8 -> 0.03253
Loss epoch 9 -> 0.02455
Loss epoch 10 -> 0.02528
Loss epoch 11 -> 0.02589
Loss epoch 12 -> 0.02131
Loss epoch 13 -> 0.03434
Loss epoch 14 -> 0.02074
Loss epoch 15 -> 0.02288
Loss epoch 16 -> 0.02879
Loss epoch 17 -> 0.01776
Loss epoch 18 -> 0.02715
Loss epoch 19 -> 0.03305
Loss epoch 20 -> 0.02896
Loss epoch 21 -> 0.02487
Loss epoch 22 -> 0.01830
Loss epoch 23 -> 0.10038
Loss epoch 24 -> 0.02952
Loss epoch 25 -> 0.01498
Loss epoch 26 -> 0.00363
Loss epoch 27 -> 0.00132
Loss epoch 28 -> 0.00507
Loss epoch 29 -> 0.01414
Loss epoch 30 -> 0.01419
Loss epoch 31 -> 0.00935
Loss epoch 32 -> 0.00463
Loss epoch 33 -> 0.00292
Loss epoch 34 -> 0.00146
Loss epoch 35 -> 0.02307
Loss epoch 36 -> 0.02354
Loss epoch 37 -> 0.01458
Loss epoch 38 -> 0.00689
wandb: uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: Test/Accuracy â–â–…â–…â–„â–†â–‡â–…â–‡â–‡â–‡â–…â–‡â–ˆâ–†â–‡â–†â–†â–†â–†â–†â–†â–…â–†â–†â–†â–…â–†â–†â–…â–†â–†â–†â–†â–‡â–†â–†â–…â–†â–†â–‡
wandb:    Train/Loss â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb: Test/Accuracy 0.901
wandb:    Train/Loss 0.00209
wandb:         epoch 39
wandb: 
wandb: ðŸš€ View run Training on midjourney dataset - Add tokens 3 at: https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/5ukenb5o
wandb: â­ï¸ View project at: https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250314_115135-5ukenb5o/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250314_123343-n6ee9zbh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Training on midjourney dataset - Add tokens 4
wandb: â­ï¸ View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: ðŸš€ View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/n6ee9zbh
Loss epoch 39 -> 0.00209
end...
Accuracy : 0.901
Classification report:
              precision    recall  f1-score   support

          ia       0.88      0.92      0.90       500
      nature       0.92      0.88      0.90       500

    accuracy                           0.90      1000
   macro avg       0.90      0.90      0.90      1000
weighted avg       0.90      0.90      0.90      1000

-----------------------------------------------------------------------------------------------------------
Additional tokens : 4
Training...
Loss epoch 0 -> 1.30433
Loss epoch 1 -> 0.52257
Loss epoch 2 -> 0.25078
Loss epoch 3 -> 0.10711
Loss epoch 4 -> 0.07309
Loss epoch 5 -> 0.05414
Loss epoch 6 -> 0.04185
Loss epoch 7 -> 0.03780
Loss epoch 8 -> 0.02001
Loss epoch 9 -> 0.02270
Loss epoch 10 -> 0.01541
Loss epoch 11 -> 0.02881
Loss epoch 12 -> 0.01152
Loss epoch 13 -> 0.01626
Loss epoch 14 -> 0.02927
Loss epoch 15 -> 0.02132
Loss epoch 16 -> 0.01056
Loss epoch 17 -> 0.02183
Loss epoch 18 -> 0.01641
Loss epoch 19 -> 0.01945
Loss epoch 20 -> 0.01826
Loss epoch 21 -> 0.02049
Loss epoch 22 -> 0.01638
Loss epoch 23 -> 0.01132
Loss epoch 24 -> 0.04134
Loss epoch 25 -> 0.03838
Loss epoch 26 -> 0.03232
Loss epoch 27 -> 0.02058
Loss epoch 28 -> 0.00333
Loss epoch 29 -> 0.00480
Loss epoch 30 -> 0.00632
Loss epoch 31 -> 0.00394
Loss epoch 32 -> 0.00041
Loss epoch 33 -> 0.00005
Loss epoch 34 -> 0.00002
Loss epoch 35 -> 0.00002
Loss epoch 36 -> 0.00002
Loss epoch 37 -> 0.00001
Loss epoch 38 -> 0.00001
wandb:                                                                                
wandb: 
wandb: Run history:
wandb: Test/Accuracy â–â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:    Train/Loss â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb: Test/Accuracy 0.883
wandb:    Train/Loss 1e-05
wandb:         epoch 39
wandb: 
wandb: ðŸš€ View run Training on midjourney dataset - Add tokens 4 at: https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/n6ee9zbh
wandb: â­ï¸ View project at: https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20250314_123343-n6ee9zbh/logs
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /home/users/r/rasolof2/BCs_emmanuelrasolofo/BCs_EmmanuelRasolofo/wandb/run-20250314_131552-kbxwcjxk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Training on midjourney dataset - Add tokens 5
wandb: â­ï¸ View project at https://wandb.ai/manurslf301/Encoder-DecoderProject
wandb: ðŸš€ View run at https://wandb.ai/manurslf301/Encoder-DecoderProject/runs/kbxwcjxk
Loss epoch 39 -> 0.00001
end...
Accuracy : 0.883
Classification report:
              precision    recall  f1-score   support

          ia       0.87      0.90      0.88       500
      nature       0.89      0.87      0.88       500

    accuracy                           0.88      1000
   macro avg       0.88      0.88      0.88      1000
weighted avg       0.88      0.88      0.88      1000

-----------------------------------------------------------------------------------------------------------
Additional tokens : 5
Training...
Loss epoch 0 -> 1.02193
Loss epoch 1 -> 0.25708
Loss epoch 2 -> 0.09956
Loss epoch 3 -> 0.05732
Loss epoch 4 -> 0.04232
Loss epoch 5 -> 0.02939
Loss epoch 6 -> 0.04533
Loss epoch 7 -> 0.03875
Loss epoch 8 -> 0.02388
Loss epoch 9 -> 0.01893
Loss epoch 10 -> 0.03714
Loss epoch 11 -> 0.02283
Loss epoch 12 -> 0.01550
Loss epoch 13 -> 0.01865
Loss epoch 14 -> 0.03189
Loss epoch 15 -> 0.01714
